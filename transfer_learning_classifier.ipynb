{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaQVfSghjk49lKaNITOWap",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hartiel/Transfer-Learning-Classifier/blob/main/transfer_learning_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4iPrc5tkbHNq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIG AND CONSTANTS ---\n",
        "# Set URLs and temp directories\n",
        "DATASET_URL = \"https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip\"\n",
        "LOCAL_ZIP = \"/tmp/cats-and-dogs.zip\"\n",
        "BASE_DIR = '/tmp/cats-v-dogs'"
      ],
      "metadata": {
        "id": "6KAIEvwOHav0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "v_HouGPQYFsW",
        "outputId": "32cd4a7a-204c-4596-ecb5-fe64c3950ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Start dataset downloading\n",
            "--2025-11-27 14:02:55--  https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.44.74.17, 2600:1407:7400:1184::317f, 2600:1407:7400:1187::317f\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.44.74.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824887076 (787M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
            "\n",
            "/tmp/cats-and-dogs. 100%[===================>] 786.67M  63.5MB/s    in 13s     \n",
            "\n",
            "2025-11-27 14:03:08 (61.6 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824887076/824887076]\n",
            "\n",
            ">>> Extract files...\n"
          ]
        }
      ],
      "source": [
        "# --- DOWNLOAD AND EXTRACT DATA ---\n",
        "print(f\">>> Start dataset downloading\")\n",
        "!wget --no-check-certificate \"{DATASET_URL}\" -O \"{LOCAL_ZIP}\"\n",
        "\n",
        "print(\">>> Extract files...\")\n",
        "with zipfile.ZipFile(LOCAL_ZIP, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/tmp')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- DATA CLEANING AND SPLIT ---\n",
        "# Directory reset for incorrect data\n",
        "if os.path.exists(BASE_DIR):\n",
        "    shutil.rmtree(BASE_DIR)\n",
        "\n",
        "# Directory structure Keras default\n",
        "for root in ['training', 'testing']:\n",
        "    for label in ['cats', 'dogs']:\n",
        "        os.makedirs(os.path.join(BASE_DIR, root, label))\n",
        "\n",
        "# Raw images process,  remove corrupt files (0 bytes or invalid headers)\n",
        "# and random split for avoid ordering bias.\n",
        "def sanity_check_and_split(source, training_dir, testing_dir, split_size):\n",
        "    valid_files = []\n",
        "\n",
        "    # Integrity validation\n",
        "    for filename in os.listdir(source):\n",
        "        file_path = os.path.join(source, filename)\n",
        "\n",
        "        if os.path.getsize(file_path) > 0:\n",
        "            valid_files.append(filename)\n",
        "        else:\n",
        "            print(f\"Void file ignored: {filename}\")\n",
        "\n",
        "    # Shuffle & Split (90/10)\n",
        "    training_length = int(len(valid_files) * split_size)\n",
        "    testing_length = int(len(valid_files) - training_length)\n",
        "    shuffled_set = random.sample(valid_files, len(valid_files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[-testing_length:]\n",
        "\n",
        "    # File ordering\n",
        "    for filename in training_set:\n",
        "        copyfile(os.path.join(source, filename), os.path.join(training_dir, filename))\n",
        "    for filename in testing_set:\n",
        "        copyfile(os.path.join(source, filename), os.path.join(testing_dir, filename))\n",
        "\n",
        "# Clean pipeline execution\n",
        "print(\">>> Processing and cleaning images (may take time)...\")\n",
        "sanity_check_and_split(\"/tmp/PetImages/Cat/\",\n",
        "                       f\"{BASE_DIR}/training/cats/\",\n",
        "                       f\"{BASE_DIR}/testing/cats/\",\n",
        "                       0.9)\n",
        "sanity_check_and_split(\"/tmp/PetImages/Dog/\",\n",
        "                       f\"{BASE_DIR}/training/dogs/\",\n",
        "                       f\"{BASE_DIR}/testing/dogs/\",\n",
        "                       0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueoar602bjar",
        "outputId": "2228a93b-7e50-4b8d-b661-d8f442aa3087"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Processing and cleaning images (may take time)...\n",
            "Void file ignored: 666.jpg\n",
            "Void file ignored: 11702.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- DATA GENERATORS (Streaming Middleware) ---\n",
        "# pixel sanitizing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Batch loader\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    f'{BASE_DIR}/training/',\n",
        "    target_size=(160, 160), # Input shape MobileNetV2\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    f'{BASE_DIR}/testing/',\n",
        "    target_size=(160, 160),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENWWWcdpSXBA",
        "outputId": "7ebe3635-19c6-41b4-be42-ec768b4ef338"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22498 images belonging to 2 classes.\n",
            "Found 2500 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TRANSFER LEARNING ARCHITECTURE ---\n",
        "# Load MobileNetV2 with pre-trained weights\n",
        "base_model = MobileNetV2(input_shape=(160, 160, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False # Freeze the base model to preserve the learned features\n",
        "\n",
        "# Define the custom classification head\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(), # Flatten 3D feature map into 1D vector\n",
        "    layers.Dropout(0.2), # Regularization to prevent overfitting\n",
        "    layers.Dense(1, activation='sigmoid') # Binary output\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf-l2nyxWlNB",
        "outputId": "ddbc553a-58ea-4e35-906c-82876082b33b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MODEL EXECUTION ---\n",
        "print(\">>> Starting model training...\")\n",
        "# The .fit() method triggers the training loop.\n",
        "# It returns a 'History' object containing all metrics for every epoch.\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=3,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "# --- METRICS VISUALIZATION ---\n",
        "# Extracting logs from the history object (Analagous to parsing a log JSON)\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Setting up the Dashboard (Matplotlib)\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Subplot 1: Accuracy (Higher is better)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label='Train Accuracy')\n",
        "plt.plot(val_acc, label='Val Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Accuracy Evolution')\n",
        "\n",
        "# Subplot 2: Loss (Lower is better)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label='Train Loss')\n",
        "plt.plot(val_loss, label='Val Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Loss Evolution')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXVQb3qjWnCe",
        "outputId": "21808a8e-cd54-4e70-e139-ae4ac24bde9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Starting model training...\n",
            "Epoch 1/3\n",
            "\u001b[1m428/704\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 708ms/step - accuracy: 0.9808 - loss: 0.0534"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m673/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m21s\u001b[0m 710ms/step - accuracy: 0.9803 - loss: 0.0544"
          ]
        }
      ]
    }
  ]
}